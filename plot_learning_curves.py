import os
import matplotlib.pyplot as plt
import numpy as np

# Define paths for different models - use the actual filenames generated by your training scripts
reward_logs = {
    "PPO": "logs/ActorCriticCnnPolicy_eval.npy",  # PPO typically uses ActorCriticCnnPolicy
    "A2C": "logs/ActorCriticCnnPolicy_eval.npy",  # A2C also uses ActorCriticCnnPolicy
    "Hybrid": "logs/Hybrid_CNNTransformer_eval.npy",  # Custom name for your hybrid model
}

# Find all log files automatically
log_dir = "logs"
if os.path.exists(log_dir):
    all_logs = {}
    for filename in os.listdir(log_dir):
        if filename.endswith("_eval.npy"):
            # Extract model name from filename
            model_name = filename.replace("_eval.npy", "")
            all_logs[model_name] = os.path.join(log_dir, filename)

    # If we found logs, use those instead
    if all_logs:
        print(f"Found log files: {list(all_logs.keys())}")
        reward_logs = all_logs

plt.figure(figsize=(10, 6))
for agent_name, file_path in reward_logs.items():
    if os.path.exists(file_path):
        print(f"Loading data from {file_path}")
        rewards = np.load(file_path)

        # Apply smoothing if there are enough points
        if len(rewards) >= 10:
            smoothed = np.convolve(rewards, np.ones(10) / 10, mode="valid")
            plt.plot(smoothed, label=f"{agent_name} (smoothed)")
        else:
            print(
                f"Warning: Not enough data points for {agent_name} to apply smoothing"
            )
            plt.plot(rewards, label=agent_name)
    else:
        print(f"Warning: File not found - {file_path}")

plt.title("Learning Curves - Average Reward")
plt.xlabel("Episode")
plt.ylabel("Reward")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("learning_curves.png")
plt.show()
